decay=0.005
)
neural_mod <- train(x=data_df_train,y = response_train,
method = "mlpWeightDecayML",
linear.output = TRUE,
tuneGrid = neuralGrid, # cannot pass parameter hidden directly!!
trControl = trainControl(method = "none"))
neural_pred <- predict(neural_mod,
newdata = data_df_test, prob=TRUE)
neural_cm <- confusionMatrix(neural_pred, as.factor(meta[-trainIndex, ]$top))
neural_cm
neuralGrid <-expand.grid(
layer1 = 4,
layer2 = 4,
layer3 = 0,
decay=0.005
)
neural_mod <- train(x=data_df_train,y = response_train,
method = "mlpWeightDecayML",
tuneGrid = neuralGrid, # cannot pass parameter hidden directly!!
trControl = trainControl(method = "none"))
neural_pred <- predict(neural_mod,
newdata = data_df_test, prob=TRUE)
neural_cm <- confusionMatrix(neural_pred, as.factor(meta[-trainIndex, ]$top))
neural_cm
neuralGrid <-expand.grid(
layer1 = 10,
layer2 = 5,
layer3 = 3,
decay=0.005
)
neural_mod <- train(x=data_df_train,y = response_train,
method = "mlpWeightDecayML",
tuneGrid = neuralGrid, # cannot pass parameter hidden directly!!
trControl = trainControl(method = "none"))
neural_pred <- predict(neural_mod,
newdata = data_df_test, prob=TRUE)
neural_cm <- confusionMatrix(neural_pred, as.factor(meta[-trainIndex, ]$top))
neural_cm
#comparaison des modèles
mod_results <- rbind(
nb_cm$overall,
nnet_cm$overall,
ranger_cm$overall
) %>%
as.data.frame() %>%
mutate(model = c("Naive-Bayes", "Neural network","RF"))
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
library(tidytext)
library(caret)
df<-readRDS("df_nrcliwc.rds")
#codage des deux classes
data<-df %>%
select(text, retweets,year) %>%
filter(year>2016)
median<-round(median(data$retweets),1)
data<-data %>%
mutate(retweets_cl=ifelse(retweets>median, "yes","no"))
ggplot(data, aes(retweets))+geom_histogram(binwidth = 0.1)+theme_minimal()+labs(title=paste0("médiane = ",median))+scale_x_log10()
data$id<-row.names(data)
ggplot(data, aes(retweets_cl))+geom_bar()
#nettoyage des données
##les liens
data_clean <- data %>%
mutate(top = retweets_cl,
text = str_replace_all(text, " ?(f|ht)tp(s?)://(.*)[.][a-z]+", "")) %>%
select(id, top, text)
## les stop_word
data_counts <- map_df(1:3,
~ unnest_tokens(data_clean, word, text,
token = "ngrams", n = .x)) %>%
anti_join(stop_words, by = "word") %>%
count(id, word, sort = TRUE)
## mots assez frequents
words_10 <- data_counts %>%
group_by(word) %>%
summarise(n = n()) %>%
filter(n >= 30) %>%
select(word)%>%drop_na()
#we will right-join this to our data.frame before we will calculate the tf_idf and cast it to a document term matrix.
data_dtm <- data_counts %>%
right_join(words_10, by = "word") %>%
bind_tf_idf(word, id, n) %>%
cast_dtm(id, word, tf_idf)
#We create this meta data.frame which acts as a intermediate from our first data set since some tweets might have disappeared completely after the reduction.
meta <- tibble(id = as.character(dimnames(data_dtm)[[1]])) %>%
left_join(data_clean[!duplicated(data_clean$id), ], by = "id")
trainIndex <- createDataPartition(meta$top, p = 0.7, list = FALSE, times = 1) #on partitionne
data_df_train <- data_dtm[trainIndex, ] %>% as.matrix() %>% as.data.frame() #on definit le training set
data_df_test <- data_dtm[-trainIndex, ] %>% as.matrix() %>% as.data.frame() #on définit le test set
response_train <- meta$top[trainIndex] #on définit l'annotation
trctrl <- trainControl(method = "cv", 3, classProbs=TRUE, savePredictions = TRUE) # on définit la stratégie d'entrainement. Ici on utilise une méthode de cross validation fondée sur un découpage en 5 échantillons.
nb_mod <- train(x = data_df_train,
y = as.factor(response_train),
method = "naive_bayes",
trControl = trctrl,
tuneGrid = data.frame(laplace = 0.5,
usekernel = FALSE,
adjust = FALSE))
library(MLeval)
nb_mod$results
nb_pred <- predict(nb_mod,
newdata = data_df_test, prob=TRUE)
nb_cm <- confusionMatrix(nb_pred, as.factor(meta[-trainIndex, ]$top))
nb_cm
##rdf
trctrl <- trainControl(method = "cv", 3,classProbs=TRUE, savePredictions = TRUE)
model_grid <- expand.grid(
mtry = 20                                    # mtry specified here
,splitrule = "gini"
,min.node.size = 20
)
ranger_mod <- train(x = data_df_train,
y = as.factor(response_train),
method = "ranger",
trControl = trctrl,tuneGrid = model_grid,
importance="impurity")
ranger_pred <- predict(ranger_mod,
newdata = data_df_test, prob=TRUE)
ranger_cm <- confusionMatrix(ranger_pred, as.factor(meta[-trainIndex, ]$top))
ranger_cm
##nn
trctrl <- trainControl(method = "cv", 3,classProbs=TRUE, savePredictions = TRUE)
nnet_mod <- train(x = data_df_train,
y = as.factor(response_train),
method = "nnet",
trControl = trctrl,
tuneGrid = data.frame(size = 2,
decay = 0.001),
MaxNWts = 15000, importance="impurity")
nnet_pred <- predict(nnet_mod,
newdata = data_df_test, prob=TRUE)
nnet_cm <- confusionMatrix(nnet_pred, as.factor(meta[-trainIndex, ]$top))
nnet_cm
#nnet_mod$finalModel
library(plotROC)
library(MLeval)
res <- evalm(list(nnet_mod,nb_mod, ranger_mod),gnames=c('nn','nb', 'rf'))
#explication
library(vip)
vip1<-vip(nnet_mod, num_features = 40, geom = "point", horizontal = TRUE,
aesthetics = list(color = "firebrick", shape = 1, size = 3)) +
theme_light()
vip2<-vip(nb_mod, num_features = 40, geom = "point", horizontal = TRUE,
aesthetics = list(color = "firebrick", shape = 1, size = 3)) +
theme_light()
#comparaison des modèles
mod_results <- rbind(
nb_cm$overall,
nnet_cm$overall,
ranger_cm$overall
) %>%
as.data.frame() %>%
mutate(model = c("Naive-Bayes", "Neural network","RF"))
mod_results %>%
ggplot(aes(model, Accuracy)) +
geom_bar() +
ylim(0, 1) +
geom_hline(yintercept = mod_results$AccuracyNull[1],
color = "red")
#comparaison des modèles
mod_results <- rbind(
nb_cm$overall,
nnet_cm$overall,
ranger_cm$overall
) %>%
as.data.frame() %>%
mutate(model = c("Naive-Bayes", "Neural network","RF"))
mod_results %>%
ggplot(aes(model, Accuracy)) +
geom_bar() +
ylim(0, 1) +
geom_hline(yintercept = mod_results$AccuracyNull[1],
color = "red")
trctrl <- trainControl(method = "cv", 3 ,classProbs = TRUE)
neuralGrid <-expand.grid(
layer1 = 8,
layer2 = 4,
layer3 = 2,
decay=0.005
)
neural_mod <- train(x=data_df_train,y = response_train,
method = "mlpWeightDecayML",
tuneGrid = neuralGrid, # cannot pass parameter hidden directly!!
trControl = trainControl(method = "none"))
neural_pred <- predict(neural_mod,
newdata = data_df_test, prob=TRUE)
neural_cm <- confusionMatrix(neural_pred, as.factor(meta[-trainIndex, ]$top))
neural_cm
#comparaison des modèles
mod_results <- rbind(
nb_cm$overall,
nnet_cm$overall,
ranger_cm$overall
) %>%
as.data.frame() %>%
mutate(model = c("Naive-Bayes", "Neural network","RF"))
mod_results %>%
ggplot(aes(model, Accuracy)) +
geom_bar() +
ylim(0, 1) +
geom_hline(yintercept = mod_results$AccuracyNull[1],
color = "red")
#tuning
trctrl <- trainControl(method = "cv", 3,classProbs = TRUE)
nnetGrid <-  expand.grid(size = seq(from = 1, to = 4, by = 1),
decay = seq(from = 0.000, to = 0.005, by = 0.0005))
nnet_mod_t <- train(x=data_df_train,
y = response_train,
method = "nnet",
trControl = trctrl, tuneGrid=nnetGrid, MaxNWts = 16000)
plot(nnet_mod_t)
nb_mod$results
nb_mod$results
nb_pred <- predict(nb_mod,
newdata = data_df_test, prob=TRUE)
library(MLeval)
nb_mod$results
nb_pred <- predict(nb_mod,
newdata = data_df_test, prob=TRUE)
nb_cm <- confusionMatrix(nb_pred, as.factor(meta[-trainIndex, ]$top))
nb_cm
library(MLeval)
nb_mod$results
nb_pred <- predict(nb_mod,
newdata = data_df_test, prob=TRUE)
nb_cm <- confusionMatrix(nb_pred, as.factor(meta[-trainIndex, ]$top))
nb_cm
ranger_mod$results
nnet_pred <- predict(nnet_mod,
newdata = data_df_test, prob=TRUE)
nnet_cm <- confusionMatrix(nnet_pred, as.factor(meta[-trainIndex, ]$top))
nnet_cm
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
library(tidytext)
library(caret)
df<-readRDS("df_nrcliwc.rds")
#codage des deux classes
data<-df %>%
select(text, retweets,year) %>%
filter(year>2016)
median<-round(median(data$retweets),1)
data<-data %>%
mutate(retweets_cl=ifelse(retweets>median, "yes","no"))
ggplot(data, aes(retweets))+geom_histogram(binwidth = 0.1)+theme_minimal()+labs(title=paste0("médiane = ",median))+scale_x_log10()
data$id<-row.names(data)
ggplot(data, aes(retweets_cl))+geom_bar()
#nettoyage des données
##les liens
data_clean <- data %>%
mutate(top = retweets_cl,
text = str_replace_all(text, " ?(f|ht)tp(s?)://(.*)[.][a-z]+", "")) %>%
select(id, top, text)
## les stop_word
data_counts <- map_df(1:3,
~ unnest_tokens(data_clean, word, text,
token = "ngrams", n = .x)) %>%
anti_join(stop_words, by = "word") %>%
count(id, word, sort = TRUE)
## mots assez frequents
words_10 <- data_counts %>%
group_by(word) %>%
summarise(n = n()) %>%
filter(n >= 30) %>%
select(word)%>%drop_na()
#we will right-join this to our data.frame before we will calculate the tf_idf and cast it to a document term matrix.
data_dtm <- data_counts %>%
right_join(words_10, by = "word") %>%
bind_tf_idf(word, id, n) %>%
cast_dtm(id, word, tf_idf)
#We create this meta data.frame which acts as a intermediate from our first data set since some tweets might have disappeared completely after the reduction.
meta <- tibble(id = as.character(dimnames(data_dtm)[[1]])) %>%
left_join(data_clean[!duplicated(data_clean$id), ], by = "id")
trainIndex <- createDataPartition(meta$top, p = 0.7, list = FALSE, times = 1) #on partitionne
data_df_train <- data_dtm[trainIndex, ] %>% as.matrix() %>% as.data.frame() #on definit le training set
data_df_test <- data_dtm[-trainIndex, ] %>% as.matrix() %>% as.data.frame() #on définit le test set
response_train <- meta$top[trainIndex] #on définit l'annotation
trctrl <- trainControl(method = "cv", 3, classProbs=TRUE, savePredictions = TRUE) # on définit la stratégie d'entrainement. Ici on utilise une méthode de cross validation fondée sur un découpage en 5 échantillons.
nb_mod <- train(x = data_df_train,
y = as.factor(response_train),
method = "naive_bayes",
trControl = trctrl,
tuneGrid = data.frame(laplace = 1,
usekernel = FALSE,
adjust = FALSE))
library(MLeval)
nb_mod$results
nb_pred <- predict(nb_mod,
newdata = data_df_test, prob=TRUE)
nb_cm <- confusionMatrix(nb_pred, as.factor(meta[-trainIndex, ]$top))
nb_cm
##rdf
trctrl <- trainControl(method = "cv", 3,classProbs=TRUE, savePredictions = TRUE)
model_grid <- expand.grid(
mtry = 20                                    # mtry specified here
,splitrule = "gini"
,min.node.size = 20
)
ranger_mod <- train(x = data_df_train,
y = as.factor(response_train),
method = "ranger",
trControl = trctrl,tuneGrid = model_grid,
importance="impurity")
ranger_mod$results
ranger_pred <- predict(ranger_mod,
newdata = data_df_test, prob=TRUE)
ranger_cm <- confusionMatrix(ranger_pred, as.factor(meta[-trainIndex, ]$top))
ranger_cm
##nn
trctrl <- trainControl(method = "cv", 3,classProbs=TRUE, savePredictions = TRUE)
nnet_mod <- train(x = data_df_train,
y = as.factor(response_train),
method = "nnet",
trControl = trctrl,
tuneGrid = data.frame(size = 2,
decay = 0.001),
MaxNWts = 15000, importance="impurity")
nnet_pred <- predict(nnet_mod,
newdata = data_df_test, prob=TRUE)
nnet_cm <- confusionMatrix(nnet_pred, as.factor(meta[-trainIndex, ]$top))
nnet_cm
#nnet_mod$finalModel
library(plotROC)
library(MLeval)
res <- evalm(list(nnet_mod,nb_mod, ranger_mod),gnames=c('nn','nb', 'rf'))
knitr::opts_chunk$set(echo = TRUE, cache=TRUE, message=FALSE,warning=FALSE)
library(tidyverse)
library(tidytext)
library(caret)
df<-readRDS("df_nrcliwc.rds")
#explication
library(vip)
vip1<-vip(nnet_mod, num_features = 40, geom = "point", horizontal = TRUE,
aesthetics = list(color = "firebrick", shape = 1, size = 3)) +
theme_light()
vip2<-vip(nb_mod, num_features = 40, geom = "point", horizontal = TRUE,
aesthetics = list(color = "firebrick", shape = 1, size = 3)) +
theme_light()
vip3<-vip(ranger_mod, num_features = 40, geom = "point", horizontal = TRUE,
aesthetics = list(color = "firebrick", shape = 1, size = 3)) +
theme_light()
grid.arrange(vip1, vip3, col=3)
grid.arrange(vip1, vip3, col=2)
vip1
vip3
p4 <- vip(nnet_mod, method = "permute", metric = "auc", pred_wrapper = predict, target = c("abolish"),reference_class = "neg")
trctrl <- trainControl(method = "cv", 3 ,classProbs = TRUE)
neuralGrid <-expand.grid(
layer1 = 8,
layer2 = 4,
layer3 = 2,
decay=0.005
)
neural_mod <- train(x=data_df_train,y = response_train,
method = "mlpWeightDecayML",
tuneGrid = neuralGrid, # cannot pass parameter hidden directly!!
trControl = trainControl(method = "none"))
neural_pred <- predict(neural_mod,
newdata = data_df_test, prob=TRUE)
neural_cm <- confusionMatrix(neural_pred, as.factor(meta[-trainIndex, ]$top))
neural_cm
trctrl <- trainControl(method = "cv", 3 ,classProbs = TRUE)
neuralGrid <-expand.grid(
layer1 = 2,
layer2 = 2,
layer3 = 2,
decay=0.005
)
neural_mod <- train(x=data_df_train,y = response_train,
method = "mlpWeightDecayML",
tuneGrid = neuralGrid, # cannot pass parameter hidden directly!!
trControl = trainControl(method = "none"))
neural_pred <- predict(neural_mod,
newdata = data_df_test, prob=TRUE)
neural_cm <- confusionMatrix(neural_pred, as.factor(meta[-trainIndex, ]$top))
neural_cm
trctrl <- trainControl(method = "cv", 3 ,classProbs = TRUE)
neuralGrid <-expand.grid(
layer1 = 2,
layer2 = 2,
layer3 = 2,
decay=0.0005
)
neural_mod <- train(x=data_df_train,y = response_train,
method = "mlpWeightDecayML",
tuneGrid = neuralGrid, # cannot pass parameter hidden directly!!
trControl = trainControl(method = "none"))
neural_pred <- predict(neural_mod,
newdata = data_df_test, prob=TRUE)
neural_cm <- confusionMatrix(neural_pred, as.factor(meta[-trainIndex, ]$top))
neural_cm
trctrl <- trainControl(method = "cv", 3 ,classProbs = TRUE)
neuralGrid <-expand.grid(
layer1 = 3,
layer2 = 3,
layer3 = 0,
decay=0.0005
)
neural_mod <- train(x=data_df_train,y = response_train,
method = "mlpWeightDecayML",
tuneGrid = neuralGrid, # cannot pass parameter hidden directly!!
trControl = trainControl(method = "none"))
neural_pred <- predict(neural_mod,
newdata = data_df_test, prob=TRUE)
neural_cm <- confusionMatrix(neural_pred, as.factor(meta[-trainIndex, ]$top))
neural_cm
#comparaison des modèles
mod_results <- rbind(
nb_cm$overall,
nnet_cm$overall,
ranger_cm$overall
) %>%
as.data.frame() %>%
mutate(model = c("Naive-Bayes", "Neural network","RF"))
mod_results %>%
ggplot(aes(model, Accuracy)) +
geom_bar() +
ylim(0, 1) +
geom_hline(yintercept = mod_results$AccuracyNull[1],
color = "red")
mod_results %>%
ggplot(aes(model, Accuracy)) +
geom_bar(stat="identity") +
ylim(0, 1) +
geom_hline(yintercept = mod_results$AccuracyNull[1],
color = "red")
library(doParallel)
detectCores()
cl <- makePSOCKcluster(4)
registerDoParallel(cl)
library(doParallel)
cl <- makePSOCKcluster(4)
registerDoParallel(cl)
#tuning
trctrl <- trainControl(method = "cv", 3,classProbs = TRUE)
nnetGrid <-  expand.grid(size = seq(from = 1, to = 4, by = 1),
decay = seq(from = 0.000, to = 0.005, by = 0.005))
nnet_mod_t <- train(x=data_df_train,
y = response_train,
method = "nnet",
trControl = trctrl, tuneGrid=nnetGrid, MaxNWts = 16000)
stopCluster(cl)
t1<-Sys.time()
t1
library(doParallel)
cl <- makePSOCKcluster(3)
registerDoParallel(cl)
#tuning
trctrl <- trainControl(method = "cv", 3,classProbs = TRUE)
nnetGrid <-  expand.grid(size = seq(from = 1, to = 1, by = 1),
decay = seq(from = 0.000, to = 0.005, by = 0.001))
nnet_mod_t <- train(x=data_df_train,
y = response_train,
method = "nnet",
trControl = trctrl, tuneGrid=nnetGrid, MaxNWts = 16000)
plot(nnet_mod_t)
stopCluster(cl)
t2<-Sys.time()
t2-t1
t1<-Sys.time()
t1
library(doParallel)
cl <- makePSOCKcluster(3)
registerDoParallel(cl)
#tuning
trctrl <- trainControl(method = "cv", 3,classProbs = TRUE)
nnetGrid <-  expand.grid(size = seq(from = 1, to = 1, by = 1),
decay = seq(from = 0.003, to = 0.010, by = 0.001))
nnet_mod_t <- train(x=data_df_train,
y = response_train,
method = "nnet",
trControl = trctrl, tuneGrid=nnetGrid, MaxNWts = 16000)
plot(nnet_mod_t)
stopCluster(cl)
t2<-Sys.time()
t2-t1
t1<-Sys.time()
t1
library(doParallel)
cl <- makePSOCKcluster(3)
registerDoParallel(cl)
#tuning
trctrl <- trainControl(method = "cv", 3,classProbs = TRUE)
nnetGrid <-  expand.grid(size = seq(from = 1, to = 4, by = 1),
decay = seq(from = 0.003, to = 0.010, by = 0.001))
nnet_mod_t <- train(x=data_df_train,
y = response_train,
method = "nnet",
trControl = trctrl, tuneGrid=nnetGrid, MaxNWts = 16000)
plot(nnet_mod_t)
stopCluster(cl)
t2<-Sys.time()
t2-t1
t1<-Sys.time()
t1
library(doParallel)
cl <- makePSOCKcluster(3)
registerDoParallel(cl)
#tuning
trctrl <- trainControl(method = "cv", 3,classProbs = TRUE)
nnetGrid <-  expand.grid(size = seq(from = 1, to = 4, by = 1),
decay = seq(from = 0.003, to = 0.030, by = 0.002))
nnet_mod_t <- train(x=data_df_train,
y = response_train,
method = "nnet",
trControl = trctrl, tuneGrid=nnetGrid, MaxNWts = 16000)
plot(nnet_mod_t)
stopCluster(cl)
t2<-Sys.time()
t2-t1
